import asyncio
import websockets
import json
import base64
import hashlib
import os
from typing import Optional, Dict, Set
import time
from dataclasses import dataclass

@dataclass
class ChunkInfo:
    index: int
    data: bytes
    size: int
    retry_count: int = 0
    uploaded: bool = False

class FileUploadTester:
    def __init__(self, ws_uri: str, file_path: str, max_concurrent: int = 5):
        self.ws_uri = ws_uri
        self.file_path = file_path
        self.chunk_size = 64 * 1024  # 64KB per chunk
        self.max_concurrent = max_concurrent  # æœ€å¤§å¹¶å‘æ•°
        self.max_retries = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
        self.stream_id = None
        self.chunks: Dict[int, ChunkInfo] = {}
        self.upload_semaphore = asyncio.Semaphore(max_concurrent)
        self.failed_chunks: Set[int] = set()
        
        # æ¶ˆæ¯è·¯ç”±æœºåˆ¶
        self.response_futures: Dict[str, asyncio.Future] = {}
        self.message_receiver_task = None
        
    async def connect_and_upload(self):
        """è¿æ¥åˆ°WebSocketå¹¶ä¸Šä¼ æ–‡ä»¶"""
        async with websockets.connect(self.ws_uri) as ws:
            print(f"å·²è¿æ¥åˆ° {self.ws_uri}")
            
            # å¯åŠ¨æ¶ˆæ¯æ¥æ”¶å™¨
            self.message_receiver_task = asyncio.create_task(self._message_receiver(ws))
            
            try:
                # å‡†å¤‡æ–‡ä»¶æ•°æ®
                file_info = self.prepare_file()
                if not file_info:
                    return
                    
                print(f"æ–‡ä»¶ä¿¡æ¯: {file_info['filename']}, å¤§å°: {file_info['file_size']} bytes, å—æ•°: {file_info['total_chunks']}")
                print(f"å¹¶å‘è®¾ç½®: æœ€å¤§ {self.max_concurrent} ä¸ªå¹¶å‘ä¸Šä¼ ")
                
                # ç”Ÿæˆstream_id
                self.stream_id = f"upload_{hash(file_info['filename'] + str(file_info['file_size']))}"
                print(f"Stream ID: {self.stream_id}")
                
                # é‡ç½®æµï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                await self.reset_stream(ws)
                
                # å‡†å¤‡æ‰€æœ‰åˆ†ç‰‡
                self.prepare_chunks(file_info)
                
                # å¹¶è¡Œä¸Šä¼ åˆ†ç‰‡
                await self.upload_chunks_parallel(ws, file_info)
                
                # é‡è¯•å¤±è´¥çš„åˆ†ç‰‡
                if self.failed_chunks:
                    await self.retry_failed_chunks(ws, file_info)
                
                # å®Œæˆä¸Šä¼ 
                await self.complete_upload(ws)
                
                # ç­‰å¾…ä¸€æ®µæ—¶é—´ç¡®ä¿æ‰€æœ‰å“åº”éƒ½æ”¶åˆ°
                await asyncio.sleep(2)
                
            finally:
                # å–æ¶ˆæ¶ˆæ¯æ¥æ”¶å™¨
                if self.message_receiver_task:
                    self.message_receiver_task.cancel()
                    try:
                        await self.message_receiver_task
                    except asyncio.CancelledError:
                        pass
                
                # æ¸…ç†æœªå®Œæˆçš„Future
                for future in self.response_futures.values():
                    if not future.done():
                        future.cancel()
    
    async def _message_receiver(self, ws):
        """ä¸“é—¨çš„æ¶ˆæ¯æ¥æ”¶åç¨‹ï¼Œè´Ÿè´£åˆ†å‘å“åº”åˆ°å¯¹åº”çš„Future"""
        try:
            while True:
                message = await ws.recv()
                try:
                    data = json.loads(message)
                    echo = data.get('echo', 'unknown')
                    
                    # æŸ¥æ‰¾å¯¹åº”çš„Future
                    if echo in self.response_futures:
                        future = self.response_futures[echo]
                        if not future.done():
                            future.set_result(data)
                    else:
                        # å¤„ç†æœªé¢„æœŸçš„å“åº”
                        print(f"ğŸ“¨ æœªé¢„æœŸå“åº” [{echo}]: {data}")
                        
                except json.JSONDecodeError as e:
                    print(f"âš ï¸ JSONè§£æé”™è¯¯: {e}")
                except Exception as e:
                    print(f"âš ï¸ æ¶ˆæ¯å¤„ç†é”™è¯¯: {e}")
                    
        except asyncio.CancelledError:
            print("ğŸ”„ æ¶ˆæ¯æ¥æ”¶å™¨å·²åœæ­¢")
            raise
        except Exception as e:
            print(f"ğŸ’¥ æ¶ˆæ¯æ¥æ”¶å™¨å¼‚å¸¸: {e}")
    
    async def _send_and_wait_response(self, ws, request: dict, timeout: float = 10.0) -> Optional[dict]:
        """å‘é€è¯·æ±‚å¹¶ç­‰å¾…å“åº”"""
        echo = request.get('echo', 'unknown')
        
        # åˆ›å»ºFutureç”¨äºæ¥æ”¶å“åº”
        future = asyncio.Future()
        self.response_futures[echo] = future
        
        try:
            # å‘é€è¯·æ±‚
            await ws.send(json.dumps(request))
            
            # ç­‰å¾…å“åº”
            response = await asyncio.wait_for(future, timeout=timeout)
            return response
            
        except asyncio.TimeoutError:
            print(f"â° è¯·æ±‚è¶…æ—¶: {echo}")
            return None
        except Exception as e:
            print(f"ğŸ’¥ è¯·æ±‚å¼‚å¸¸: {echo} - {e}")
            return None
        finally:
            # æ¸…ç†Future
            if echo in self.response_futures:
                del self.response_futures[echo]
    
    def prepare_file(self):
        """å‡†å¤‡æ–‡ä»¶ä¿¡æ¯"""
        if not os.path.exists(self.file_path):
            print(f"æ–‡ä»¶ä¸å­˜åœ¨: {self.file_path}")
            return None
            
        file_size = os.path.getsize(self.file_path)
        filename = os.path.basename(self.file_path)
        total_chunks = (file_size + self.chunk_size - 1) // self.chunk_size
        
        # è®¡ç®—SHA256
        print("è®¡ç®—æ–‡ä»¶SHA256...")
        sha256_hash = hashlib.sha256()
        with open(self.file_path, 'rb') as f:
            for chunk in iter(lambda: f.read(8192), b""):
                sha256_hash.update(chunk)
        expected_sha256 = sha256_hash.hexdigest()
        
        return {
            'filename': filename,
            'file_size': file_size,
            'total_chunks': total_chunks,
            'expected_sha256': expected_sha256
        }
    
    def prepare_chunks(self, file_info):
        """é¢„è¯»å–æ‰€æœ‰åˆ†ç‰‡æ•°æ®"""
        print("é¢„è¯»å–åˆ†ç‰‡æ•°æ®...")
        with open(self.file_path, 'rb') as f:
            for chunk_index in range(file_info['total_chunks']):
                chunk_data = f.read(self.chunk_size)
                self.chunks[chunk_index] = ChunkInfo(
                    index=chunk_index,
                    data=chunk_data,
                    size=len(chunk_data)
                )
        print(f"å·²å‡†å¤‡ {len(self.chunks)} ä¸ªåˆ†ç‰‡")
    
    async def reset_stream(self, ws):
        """é‡ç½®æµ"""
        req = {
            "action": "upload_file_stream",
            "params": {
                "stream_id": self.stream_id,
                "reset": True
            },
            "echo": "reset"
        }
        
        print("å‘é€é‡ç½®è¯·æ±‚...")
        response = await self._send_and_wait_response(ws, req, timeout=5.0)
        
        if response and response.get('echo') == 'reset':
            print("âœ… æµé‡ç½®å®Œæˆ")
        else:
            print(f"âš ï¸ é‡ç½®å“åº”å¼‚å¸¸: {response}")
    
    async def upload_chunks_parallel(self, ws, file_info):
        """å¹¶è¡Œä¸Šä¼ æ‰€æœ‰åˆ†ç‰‡"""
        print(f"\nå¼€å§‹å¹¶è¡Œä¸Šä¼  {len(self.chunks)} ä¸ªåˆ†ç‰‡...")
        start_time = time.time()
        
        # åˆ›å»ºä¸Šä¼ ä»»åŠ¡
        tasks = []
        for chunk_index in range(file_info['total_chunks']):
            task = asyncio.create_task(
                self.upload_single_chunk(ws, chunk_index, file_info)
            )
            tasks.append(task)
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ç»Ÿè®¡ç»“æœ
        successful = sum(1 for r in results if r is True)
        failed = sum(1 for r in results if r is not True)
        
        elapsed = time.time() - start_time
        speed = file_info['file_size'] / elapsed / 1024 / 1024  # MB/s
        
        print(f"\nğŸ“Š å¹¶è¡Œä¸Šä¼ å®Œæˆ:")
        print(f"   æˆåŠŸ: {successful}/{len(self.chunks)}")
        print(f"   å¤±è´¥: {failed}")
        print(f"   è€—æ—¶: {elapsed:.2f}ç§’")
        print(f"   é€Ÿåº¦: {speed:.2f}MB/s")
        
        if failed > 0:
            print(f"âš ï¸ {failed} ä¸ªåˆ†ç‰‡ä¸Šä¼ å¤±è´¥ï¼Œå°†è¿›è¡Œé‡è¯•")
    
    async def upload_single_chunk(self, ws, chunk_index: int, file_info) -> bool:
        """ä¸Šä¼ å•ä¸ªåˆ†ç‰‡"""
        async with self.upload_semaphore:  # é™åˆ¶å¹¶å‘æ•°
            chunk = self.chunks[chunk_index]
            
            try:
                chunk_base64 = base64.b64encode(chunk.data).decode('utf-8')
                
                req = {
                    "action": "upload_file_stream",
                    "params": {
                        "stream_id": self.stream_id,
                        "chunk_data": chunk_base64,
                        "chunk_index": chunk_index,
                        "total_chunks": file_info['total_chunks'],
                        "file_size": file_info['file_size'],
                        "filename": file_info['filename'],
                        "expected_sha256": file_info['expected_sha256']
                    },
                    "echo": f"chunk_{chunk_index}"
                }
                
                # ä½¿ç”¨ç»Ÿä¸€çš„å‘é€å’Œæ¥æ”¶æ–¹æ³•
                response = await self._send_and_wait_response(ws, req, timeout=10.0)
                
                if response and response.get('echo') == f"chunk_{chunk_index}":
                    if response.get('status') == 'ok':
                        chunk.uploaded = True
                        data = response.get('data', {})
                        progress = data.get('received_chunks', 0)
                        total = data.get('total_chunks', file_info['total_chunks'])
                        print(f"âœ… å— {chunk_index + 1:3d}/{total} ({chunk.size:5d}B) - è¿›åº¦: {progress}/{total}")
                        return True
                    else:
                        error_msg = response.get('message', 'Unknown error')
                        print(f"âŒ å— {chunk_index + 1} å¤±è´¥: {error_msg}")
                        self.failed_chunks.add(chunk_index)
                        return False
                else:
                    print(f"âš ï¸ å— {chunk_index + 1} å“åº”å¼‚å¸¸æˆ–è¶…æ—¶")
                    self.failed_chunks.add(chunk_index)
                    return False
                    
            except Exception as e:
                print(f"ğŸ’¥ å— {chunk_index + 1} å¼‚å¸¸: {e}")
                self.failed_chunks.add(chunk_index)
                return False
    
    async def retry_failed_chunks(self, ws, file_info):
        """é‡è¯•å¤±è´¥çš„åˆ†ç‰‡"""
        print(f"\nğŸ”„ å¼€å§‹é‡è¯• {len(self.failed_chunks)} ä¸ªå¤±è´¥åˆ†ç‰‡...")
        
        for retry_round in range(self.max_retries):
            if not self.failed_chunks:
                break
                
            print(f"ç¬¬ {retry_round + 1} è½®é‡è¯•ï¼Œå‰©ä½™ {len(self.failed_chunks)} ä¸ªåˆ†ç‰‡")
            current_failed = self.failed_chunks.copy()
            self.failed_chunks.clear()
            
            # é‡è¯•å½“å‰å¤±è´¥çš„åˆ†ç‰‡
            retry_tasks = []
            for chunk_index in current_failed:
                task = asyncio.create_task(
                    self.upload_single_chunk(ws, chunk_index, file_info)
                )
                retry_tasks.append(task)
            
            retry_results = await asyncio.gather(*retry_tasks, return_exceptions=True)
            successful_retries = sum(1 for r in retry_results if r is True)
            
            print(f"é‡è¯•ç»“æœ: {successful_retries}/{len(current_failed)} æˆåŠŸ")
            
            if not self.failed_chunks:
                print("âœ… æ‰€æœ‰åˆ†ç‰‡é‡è¯•æˆåŠŸ!")
                break
            else:
                await asyncio.sleep(1)  # é‡è¯•é—´éš”
        
        if self.failed_chunks:
            print(f"âŒ ä»æœ‰ {len(self.failed_chunks)} ä¸ªåˆ†ç‰‡å¤±è´¥: {sorted(self.failed_chunks)}")
    
    async def complete_upload(self, ws):
        """å®Œæˆä¸Šä¼ """
        req = {
            "action": "upload_file_stream",
            "params": {
                "stream_id": self.stream_id,
                "is_complete": True
            },
            "echo": "complete"
        }
        
        print("\nå‘é€å®Œæˆè¯·æ±‚...")
        response = await self._send_and_wait_response(ws, req, timeout=10.0)
        
        if response:
            if response.get('status') == 'ok':
                data = response.get('data', {})
                print(f"âœ… ä¸Šä¼ å®Œæˆ!")
                print(f"   æ–‡ä»¶è·¯å¾„: {data.get('file_path')}")
                print(f"   æ–‡ä»¶å¤§å°: {data.get('file_size')} bytes")
                print(f"   SHA256: {data.get('sha256')}")
                print(f"   çŠ¶æ€: {data.get('status')}")
            else:
                print(f"âŒ ä¸Šä¼ å¤±è´¥: {response.get('message')}")
        else:
            print("âš ï¸ å®Œæˆè¯·æ±‚è¶…æ—¶æˆ–å¤±è´¥")

async def main():
    # é…ç½®
    WS_URI = "ws://localhost:3001"  # ä¿®æ”¹ä¸ºä½ çš„WebSocketåœ°å€
    FILE_PATH = r"C:\Users\nanaeo\Pictures\CatPicture.zip" #!!!!!!!!!!!
    MAX_CONCURRENT = 8  # æœ€å¤§å¹¶å‘ä¸Šä¼ æ•°ï¼Œå¯æ ¹æ®æœåŠ¡å™¨æ€§èƒ½è°ƒæ•´
    
    # åˆ›å»ºæµ‹è¯•æ–‡ä»¶ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if not os.path.exists(FILE_PATH):
        with open(FILE_PATH, 'w', encoding='utf-8') as f:
            f.write("è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡ä»¶ï¼Œç”¨äºæ¼”ç¤ºå¹¶è¡Œæ–‡ä»¶åˆ†ç‰‡ä¸Šä¼ åŠŸèƒ½ã€‚\n" * 100)
        print(f"âœ… åˆ›å»ºæµ‹è¯•æ–‡ä»¶: {FILE_PATH}")
    
    print("=== å¹¶è¡Œæ–‡ä»¶æµä¸Šä¼ æµ‹è¯• ===")
    print(f"WebSocket URI: {WS_URI}")
    print(f"æ–‡ä»¶è·¯å¾„: {FILE_PATH}")
    print(f"æœ€å¤§å¹¶å‘æ•°: {MAX_CONCURRENT}")
    
    try:
        tester = FileUploadTester(WS_URI, FILE_PATH, MAX_CONCURRENT)
        await tester.connect_and_upload()
        print("ğŸ‰ æµ‹è¯•å®Œæˆ!")
    except Exception as e:
        print(f"ğŸ’¥ æµ‹è¯•å‡ºé”™: {e}")

if __name__ == "__main__":
    asyncio.run(main())
